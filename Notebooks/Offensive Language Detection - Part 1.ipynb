{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b3c210",
   "metadata": {},
   "source": [
    "# OFFENSIVE LANGUAGE DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8a4dc",
   "metadata": {},
   "source": [
    "## Business Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd014bb",
   "metadata": {},
   "source": [
    "A company, that has a blog for employees, wants to develop a model for detecting offensiv language so that it can prevent employees from posting such."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ba3b0",
   "metadata": {},
   "source": [
    "## Hypothesis & Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f711541",
   "metadata": {},
   "source": [
    "The hypothesis is that we can enable software to automatically detect offensive posts by training a model with text data (tweets) that have been labelled.\n",
    "\n",
    "The objective of this Project is to:\n",
    "1. Obtain labelled (Offensive & Non offensive) Textual data\n",
    "2. Preprocess the textual data\n",
    "3. Extract features from the data\n",
    "4. Handle imbalance in the dataset\n",
    "5. Implement different models to classify the employees' posts\n",
    "6. Evaluate the perormance of the different classification models & feature extraction techniques\n",
    "7. Make recommendation to the company (What model is best suited for their business need?)\n",
    "8. Deploy the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239759db",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c50dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel --user\n",
    "#!pip install -U spacy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19eb6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f18413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "458f283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9cb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "import spacy\n",
    "import contractions\n",
    "import emoji\n",
    "import string\n",
    "from word2number import w2n\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import logging\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c463a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab747fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install -c pytorch pytorch torchvision\n",
    "\n",
    "#I had to use the % to make sure pytorch was being installed in the same environment I have my notebook running, before this I was getting 'no module found\" error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b18e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16e815",
   "metadata": {},
   "source": [
    "#### Download some components from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776479f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e425125",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7cd58",
   "metadata": {},
   "source": [
    "I obtained the Offensive Language Identification Dataset - OLID from https://scholar.harvard.edu/malmasi/olid\n",
    "\n",
    "The dataset contains annotated tweets with 3 levels. \n",
    " - The first level denotes whether the tweet is offensive (OFF) or not (NOT). \n",
    " - The second level denotes the type of the offensive tweet and could be targeted insult (TIN) or un-targeted (UNT).\n",
    " - The third level denotes the target of the offensive post categorized mainly into individual (IND), group (GRP) or other (OTH)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff52c95",
   "metadata": {},
   "source": [
    "## Part 1 - Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352774b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b15a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(r'C:\\Users\\ASUS\\Offensive_Language_Detection\\olid.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb96209",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ebec8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13240 entries, 0 to 13239\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         13240 non-null  int64 \n",
      " 1   tweet      13240 non-null  object\n",
      " 2   subtask_a  13240 non-null  object\n",
      " 3   subtask_b  4400 non-null   object\n",
      " 4   subtask_c  3876 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 517.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dcfee",
   "metadata": {},
   "source": [
    "There are 5 columns in the dataset. Now are all these columns relevant to our objective?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1549d6",
   "metadata": {},
   "source": [
    "Since the objective is to detect offensive language and I am not trying to do any additional analysis for now, I do not need subtask_b and subtask_c.\n",
    "Also, the id of the tweet does not have any effect on the nature (offensive or not) of the tweet.\n",
    "So the only columns that are relevant to the objective are 'tweet' & 'subtask_a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122e532",
   "metadata": {},
   "source": [
    "### Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01c58cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0      @USER She should ask a few native Americans wh...       OFF\n",
       "1      @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF\n",
       "2      Amazon is investigating Chinese employees who ...       NOT\n",
       "3      @USER Someone should'veTaken\" this piece of sh...       OFF\n",
       "4      @USER @USER Obama wanted liberals &amp; illega...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  @USER Sometimes I get strong vibes from people...       OFF\n",
       "13236  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...       NOT\n",
       "13237  @USER And why report this garbage.  We don't g...       OFF\n",
       "13238                                        @USER Pussy       OFF\n",
       "13239  #Spanishrevenge vs. #justice #HumanRights and ...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(labels=['id', 'subtask_b', 'subtask_c'], axis = 1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b462737",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016d7bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        0\n",
       "subtask_a    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e295f6",
   "metadata": {},
   "source": [
    "Looks like there are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36cba2",
   "metadata": {},
   "source": [
    "### Rename column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff1049",
   "metadata": {},
   "source": [
    "To make it easier to refer to the label, I'll rename the second column from subtask_a to 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f5df2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet label\n",
       "0      @USER She should ask a few native Americans wh...   OFF\n",
       "1      @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF\n",
       "2      Amazon is investigating Chinese employees who ...   NOT\n",
       "3      @USER Someone should'veTaken\" this piece of sh...   OFF\n",
       "4      @USER @USER Obama wanted liberals &amp; illega...   NOT\n",
       "...                                                  ...   ...\n",
       "13235  @USER Sometimes I get strong vibes from people...   OFF\n",
       "13236  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...   NOT\n",
       "13237  @USER And why report this garbage.  We don't g...   OFF\n",
       "13238                                        @USER Pussy   OFF\n",
       "13239  #Spanishrevenge vs. #justice #HumanRights and ...   NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(mapper = {'subtask_a':'label'}, inplace=True, axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee56aac",
   "metadata": {},
   "source": [
    "### Check the distribution of the observations i.e the proportion of offensive and and Not offensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7acdc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    66.767372\n",
       "OFF    33.232628\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize = True)* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c533d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Label distribution'}, xlabel='Label', ylabel='No of Observations'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar', title='Label distribution' , xlabel='Label', ylabel='No of Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6657ec",
   "metadata": {},
   "source": [
    "The no of observations labelled as offensive is significantly lower than and is actually less than half of the no of observations labeled as not offensive.\n",
    "\n",
    "Hence, this data set is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e984e1c",
   "metadata": {},
   "source": [
    "To prevent our model from being biased towards the majority class and to ensure the model is able to accurately predict both the minority and majority classes, we need to deal with this imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ddd78c",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80a462",
   "metadata": {},
   "source": [
    "Because some models expect numeric values for the labels, I will replace **'OFF' with 1** and **'NOT' with 0** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb58c183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    66.767372\n",
       "1    33.232628\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace(['OFF', 'NOT'], [1, 0])\n",
    "df['label'].value_counts(normalize = True)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fcd83",
   "metadata": {},
   "source": [
    "### Check the text data\n",
    "\n",
    "Lets take a look at the nature of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a90cf3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER She should ask a few native Americans what their take on this is.\n",
      "@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\n",
      "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "@USER Someone should'veTaken\" this piece of shit to a volcano. ðŸ˜‚\"\n",
      "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
      "@USER Liberals are all Kookoo !!!\n",
      "@USER @USER Oh noes! Tough shit.\n",
      "@USER was literally just talking about this lol all mass shootings like that have been set ups. itâ€™s propaganda used to divide us on major issues like gun control and terrorism\n",
      "@USER Buy more icecream!!!\n",
      "@USER Canada doesnâ€™t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n"
     ]
    }
   ],
   "source": [
    "for tweet in df['tweet'][:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9635d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in df['tweet'][2000:2020]:\n",
    "#    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376d76a",
   "metadata": {},
   "source": [
    "Looking at the few tweets printed, I can observe the following:\n",
    "1. There are punctuations like \"\",!# etc\n",
    "2. Some tweets have emojis\n",
    "3. Some tweets originally had urls which have been replaced by \"URL\"\n",
    "4. Some tweets have numbers either in numeric form like 6 or in words like \"three\"\n",
    "5. Some words have been abbrevited like \"w/\", 2nd etc.\n",
    "6. There are some contracted words like dont, couldnt etc\n",
    "7. There are a variety of uppercase, lowercase and capitalized words\n",
    "8. @USER is present in most tweets, representing profiles tagged in the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddfc20",
   "metadata": {},
   "source": [
    "Most of the observations above are not helpful as they do not  have anything to do whether the tweet is offensive or not. \n",
    "\n",
    "So, in this case they can be regarded as noise. To improve the chances of getting good results with this model, I need to clean the data and remove these things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507429f",
   "metadata": {},
   "source": [
    "## Part 2 - Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2996d",
   "metadata": {},
   "source": [
    "### Expanding Contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23589b45",
   "metadata": {},
   "source": [
    "As observed, some of the tweets contain contractions like don't, it's etc.\n",
    "If I tokenize the text with these contractions, most of these words would lose their meaning, don't will turn to do & n't which doesn't really make any sense.\n",
    "So before tokenizing, I will expand these contracted words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406d95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(contractions.fix)\n",
    "#for tweet in df['tweet'][:20]:\n",
    "#    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527845de",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Need to convert all the text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd65eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that will convert the text to lower case\n",
    "def lowercase(word):\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "982f73e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user she should ask a few native americans what their take on this is.\n",
      "@user @user go home you are drunk!!! @user #maga #trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š url\n",
      "amazon is investigating chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. url #amazon #maga #kag #china #tcot\n",
      "@user someone should'vetaken\" this piece of shit to a volcano. ðŸ˜‚\"\n",
      "@user @user obama wanted liberals &amp; illegals to move into red states\n"
     ]
    }
   ],
   "source": [
    "#apply the function\n",
    "df['tweet'] = df['tweet'].apply(lowercase)\n",
    "for tweet in df['tweet'][:5]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc676b",
   "metadata": {},
   "source": [
    "### Remove Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b77073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to remove emojis \n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.replace_emoji(text,replace='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "765549ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user she should ask a few native americans what their take on this is.\n",
      "@user @user go home you are drunk!!! @user #maga #trump2020  url\n",
      "amazon is investigating chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. url #amazon #maga #kag #china #tcot\n",
      "@user someone should'vetaken\" this piece of shit to a volcano. \"\n",
      "@user @user obama wanted liberals &amp; illegals to move into red states\n",
      "@user liberals are all kookoo !!!\n"
     ]
    }
   ],
   "source": [
    "#apply the function\n",
    "df['tweet'] = df['tweet'].apply(remove_emoji)\n",
    "for tweet in df['tweet'][:6]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97389d0",
   "metadata": {},
   "source": [
    "### Remove Punctuation marks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dbd3bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_marks = string.punctuation\n",
    "#create a function to remove punctuation marks\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', punctuation_marks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcab7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user she should ask a few native americans what their take on this is\n",
      "user user go home you are drunk user maga trump2020  url\n",
      "amazon is investigating chinese employees who are selling internal data to thirdparty sellers looking for an edge in the competitive marketplace url amazon maga kag china tcot\n",
      "user someone shouldvetaken this piece of shit to a volcano \n",
      "user user obama wanted liberals amp illegals to move into red states\n",
      "user liberals are all kookoo \n"
     ]
    }
   ],
   "source": [
    "#apply the function\n",
    "df['tweet'] = df['tweet'].apply(remove_punctuation)\n",
    "for tweet in df['tweet'][:6]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d373c",
   "metadata": {},
   "source": [
    "### Remove 'user' & 'url'\n",
    "\n",
    "Most of the tweets contain the words 'user' & 'url' which represent other profiles being tagged and web links. As these re not useful to the classification, we need to remove them too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c25954b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function emove url & user\n",
    "def remove_url_user(text):\n",
    "    text_1 = text.replace('url','')\n",
    "    return text_1.replace('user', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a27553dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function \n",
    "df['tweet'] = df['tweet'].apply(remove_url_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27af23",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Now we can split the text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2510c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92935391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'should', 'ask', 'a', 'few', 'native', 'americans', 'what', 'their', 'take', 'on', 'this', 'is']\n",
      "['go', 'home', 'you', 'are', 'drunk', 'maga', 'trump2020']\n",
      "['amazon', 'is', 'investigating', 'chinese', 'employees', 'who', 'are', 'selling', 'internal', 'data', 'to', 'thirdparty', 'sellers', 'looking', 'for', 'an', 'edge', 'in', 'the', 'competitive', 'marketplace', 'amazon', 'maga', 'kag', 'china', 'tcot']\n",
      "['someone', 'shouldvetaken', 'this', 'piece', 'of', 'shit', 'to', 'a', 'volcano']\n",
      "['obama', 'wanted', 'liberals', 'amp', 'illegals', 'to', 'move', 'into', 'red', 'states']\n",
      "['liberals', 'are', 'all', 'kookoo']\n",
      "['oh', 'noes', 'tough', 'shit']\n",
      "['was', 'literally', 'just', 'talking', 'about', 'this', 'lol', 'all', 'mass', 'shootings', 'like', 'that', 'have', 'been', 'set', 'ups', 'it', 'is', 'propaganda', 'used', 'to', 'divide', 'us', 'on', 'major', 'issues', 'like', 'gun', 'control', 'and', 'terrorism']\n"
     ]
    }
   ],
   "source": [
    "for tweet in df['tweet'][:8]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30673c3",
   "metadata": {},
   "source": [
    "### Remove numbers\n",
    "\n",
    "Some of the text contains numbers, both in numeric & word format. These numbers would most likely have no effect on the classification, so its better to remove them.\n",
    "\n",
    "To remove numbers, we need to;\n",
    "1. convert word numbers to digits\n",
    "2. remove all the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7e513f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert word to numbers\n",
    "#nltk_pos_tag for some reason tags certain words as CD e.g girl, so I have to use a tray & except block to handle this \n",
    "\n",
    "def convert_to_numeric(lists):\n",
    "    length = len(lists)\n",
    "    tags = nltk.pos_tag(lists)\n",
    "    new_list = []\n",
    "    for i in range(length):\n",
    "        if tags[i][1] == 'CD':\n",
    "            try:\n",
    "                new_list.append(w2n.word_to_num(lists[i]))\n",
    "            except:\n",
    "                new_list.append(lists[i])\n",
    "        else:\n",
    "            new_list.append(lists[i])\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5add4",
   "metadata": {},
   "source": [
    "### Convert numbers in words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93c305b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(convert_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd301e",
   "metadata": {},
   "source": [
    "### Remove all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e66b3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(lists):\n",
    "    new_list = []\n",
    "    for val in lists:\n",
    "        if not bool(re.search(r'\\d', str(val))):\n",
    "            new_list.append(val)\n",
    "    return new_list\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ff92a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a302320",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ad8c9",
   "metadata": {},
   "source": [
    "Stop words are very common words like 'the' and 'are' that would most likely not be of benefit to the classification task. \n",
    "\n",
    "For example, having the word \"the\" in a tweet has nothing to do with the tweet being offensive or not.\n",
    "\n",
    "So, to save computing time and reduce the volume of text that we have to deal with,it's better to remove these words.\n",
    "\n",
    "The spacy library has a list of stop words which I can use, but I may have to modify this list and remove certain words which might be relevant to our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90f9acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doing', 'also', 'ours', 'eight', 'sometime', 'themselves', 'mostly', 'quite', 'very', 'once', 'of', 'anyone', 'due', 'per', 'less', 'three', 'within', 'nâ€™t', 'becomes', 'nobody', 'too', 're', 'name', 'everyone', 'own', 'made', 'wherein', 'â€™ve', 'thereby', 'used', 'in', 'somewhere', 'except', 'â€™d', 'together', 'hers', 'meanwhile', 'almost', \"'ve\", 'at', 'many', 'all', 'himself', 'as', 'if', 'never', 'â€˜d', 'are', 'they', 'again', 'somehow', 'beside', 'everything', 'latter', 'six', 'latterly', 'ourselves', 'out', 'rather', 'every', 'none', 'could', 'using', 'so', 'about', 'since', 'whither', 'everywhere', 'otherwise', 'please', 'herein', 'noone', 'not', 'only', 'and', 'often', 'show', 'seeming', 'fifty', 'that', 'alone', 'do', 'enough', 'eleven', 'through', 'it', 'hereby', 'why', 'which', 'these', 'being', 'ten', 'yourselves', 'therefore', 'thereupon', 'down', 'thru', 'here', 'unless', 'this', 'well', 'regarding', 'anyway', 'without', 'whether', 'least', 'below', 'him', 'make', 'sixty', 'your', 'former', 'indeed', 'side', \"'s\", 'would', 'nowhere', 'fifteen', 'though', 'myself', 'â€™s', 'behind', 'those', 'really', 'besides', 'while', 'throughout', 'keep', 'during', 'whereafter', 'another', 'nor', 'how', 'seems', 'call', 'can', 'to', 'more', 'a', 'itself', 'others', 'â€™ll', 'afterwards', 'seem', 'should', 'toward', 'various', 'might', 'becoming', 'give', 'into', 'part', 'were', 'until', 'thence', 'always', 'â€™re', 'although', 'she', 'most', 'above', \"'re\", 'other', 'whose', 'off', 'after', 'upon', 'hereafter', 'third', 'from', 'between', 'must', 'my', \"n't\", 'whence', 'hundred', 'therein', 'was', 'first', 'either', 'several', 'hereupon', 'two', 'get', 'we', 'been', 'empty', 'see', 'move', 'whereas', 'nine', 'anyhow', 'around', 'thus', 'among', 'further', 'next', 'herself', 'with', 'each', 'twelve', 'take', 'towards', 'bottom', 'under', 'yet', 'his', \"'m\", 'or', 'over', 'sometimes', 'who', 'such', 'â€˜ll', 'against', 'across', 'thereafter', 'same', 'when', 'i', 'an', 'have', 'there', 'still', 'is', 'now', 'something', 'else', 'whole', 'her', 'even', 'he', 'cannot', 'mine', 'â€˜m', 'seemed', 'them', 'just', 'by', 'front', 'us', 'much', 'few', 'on', 'some', 'namely', 'perhaps', 'last', 'done', 'beyond', 'had', 'any', 'what', 'became', 'go', 'whoever', 'formerly', 'â€™m', 'already', 'anywhere', 'wherever', 'their', 'nâ€˜t', 'the', 'did', 'via', 'whereupon', 'five', 'than', 'where', 'amongst', 'onto', 'ever', 'because', 'both', 'does', 'put', 'me', 'moreover', 'whatever', 'whenever', 'forty', 'has', 'someone', 'top', 'am', 'amount', 'â€˜ve', 'four', 'twenty', 'neither', 'say', 'whom', 'â€˜re', 'nevertheless', 'back', 'ca', 'before', 'serious', 'up', 'its', 'be', 'no', 'along', 'full', 'nothing', 'hence', \"'ll\", 'however', 'beforehand', 'our', 'will', 'elsewhere', 'one', 'you', 'anything', 'whereby', 'become', 'yours', 'yourself', 'â€˜s', 'for', \"'d\", 'then', 'may', 'but'}\n"
     ]
    }
   ],
   "source": [
    "en = spacy.load('en_core_web_md')\n",
    "stopwords = en.Defaults.stop_words\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7f954",
   "metadata": {},
   "source": [
    "After carefully observing these stop words, none of them are offensive. Some are ngative like not, n't but they wont have any effect on this offensive classification, so I can remove all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69a8f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(lists):\n",
    "    new_list = []\n",
    "    for word in lists:\n",
    "        if word not in stopwords:\n",
    "            new_list.append(word)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0113990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd9007e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [ask, native, americans]\n",
       "1                                  [home, drunk, maga]\n",
       "2    [amazon, investigating, chinese, employees, se...\n",
       "3                [shouldvetaken, piece, shit, volcano]\n",
       "4    [obama, wanted, liberals, amp, illegals, red, ...\n",
       "5                                   [liberals, kookoo]\n",
       "6                              [oh, noes, tough, shit]\n",
       "7    [literally, talking, lol, mass, shootings, lik...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc2ee4",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd00f0",
   "metadata": {},
   "source": [
    "The last step in the preprocessing stage is lemmatization. \n",
    "\n",
    "Lemmatization is used to convert words into their root form without losing their meaning (this is the advantage lemmatization has over stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afe595c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(lists):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_list = []\n",
    "    for word in lists:\n",
    "        new_list.append(lemmatizer.lemmatize(word))\n",
    "    return new_list\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e391eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [ask, native, american]\n",
       "1                                  [home, drunk, maga]\n",
       "2    [amazon, investigating, chinese, employee, sel...\n",
       "3                [shouldvetaken, piece, shit, volcano]\n",
       "4    [obama, wanted, liberal, amp, illegals, red, s...\n",
       "5                                    [liberal, kookoo]\n",
       "6                                [oh, no, tough, shit]\n",
       "7    [literally, talking, lol, mass, shooting, like...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "588c4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13240 entries, 0 to 13239\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   13240 non-null  object\n",
      " 1   label   13240 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 207.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85993d",
   "metadata": {},
   "source": [
    "**Note: There was no extra step for removing white space because the tokenization step already took care of this**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6641659",
   "metadata": {},
   "source": [
    "### Visualize the words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e904b",
   "metadata": {},
   "source": [
    "#### To generate the word cloud, I have to combine the already tokenized word into sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0234ef03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  ask native american\n",
       "1                                      home drunk maga\n",
       "2    amazon investigating chinese employee selling ...\n",
       "3                     shouldvetaken piece shit volcano\n",
       "4          obama wanted liberal amp illegals red state\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Combine the words in each row into a sentence\n",
    "df_copy = df.copy()\n",
    "df_copy['tweet'] = df_copy['tweet'].apply(lambda x: \" \".join(x))\n",
    "df_copy['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06d64b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask native american</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home drunk maga</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon investigating chinese employee selling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shouldvetaken piece shit volcano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberal amp illegals red state</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>strong vibe people man â€™ s vibe ten million mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>benidorm creamfields maga shabby summer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>report garbage crap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>pussy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>spanishrevenge v justice humanrights freedomof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  label\n",
       "0                                    ask native american      1\n",
       "1                                        home drunk maga      1\n",
       "2      amazon investigating chinese employee selling ...      0\n",
       "3                       shouldvetaken piece shit volcano      1\n",
       "4            obama wanted liberal amp illegals red state      0\n",
       "...                                                  ...    ...\n",
       "13235  strong vibe people man â€™ s vibe ten million mu...      1\n",
       "13236            benidorm creamfields maga shabby summer      0\n",
       "13237                                report garbage crap      1\n",
       "13238                                              pussy      1\n",
       "13239  spanishrevenge v justice humanrights freedomof...      0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ad4d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask native american</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home drunk maga</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon investigating chinese employee selling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shouldvetaken piece shit volcano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberal amp illegals red state</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0                                ask native american      1\n",
       "1                                    home drunk maga      1\n",
       "2  amazon investigating chinese employee selling ...      0\n",
       "3                   shouldvetaken piece shit volcano      1\n",
       "4        obama wanted liberal amp illegals red state      0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "790b992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask native american</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home drunk maga</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon investigating chinese employee selling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shouldvetaken piece shit volcano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberal amp illegals red state</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>strong vibe people man â€™ s vibe ten million mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>benidorm creamfields maga shabby summer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>report garbage crap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>pussy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>spanishrevenge v justice humanrights freedomof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13137 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  label\n",
       "0                                    ask native american      1\n",
       "1                                        home drunk maga      1\n",
       "2      amazon investigating chinese employee selling ...      0\n",
       "3                       shouldvetaken piece shit volcano      1\n",
       "4            obama wanted liberal amp illegals red state      0\n",
       "...                                                  ...    ...\n",
       "13235  strong vibe people man â€™ s vibe ten million mu...      1\n",
       "13236            benidorm creamfields maga shabby summer      0\n",
       "13237                                report garbage crap      1\n",
       "13238                                              pussy      1\n",
       "13239  spanishrevenge v justice humanrights freedomof...      0\n",
       "\n",
       "[13137 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df_copy[df_copy['tweet'] != '']\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f072816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Split dataset into offensive & Non offensive\n",
    "df_copy_off = df_copy[df_copy['label'] == 1]['tweet']\n",
    "df_copy_not = df_copy[df_copy['label'] == 0]['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 combine all the sentences in each categray (offensive & not offensive) into one sentence\n",
    "offensive_sent = ''\n",
    "normal_sent = ''\n",
    "\n",
    "for row in df_copy_off:\n",
    "    offensive_sent = offensive_sent + ' ' + row\n",
    "\n",
    "for row in df_copy_not:\n",
    "    normal_sent = normal_sent + ' ' + row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d09c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud(background_color=\"white\", max_words=300, contour_width=3,contour_color='steelblue', width=700, height=500, scale=1, max_font_size=500, collocations=False)\n",
    "wordcloud2 = WordCloud(background_color=\"white\", max_words=300, contour_width=3,contour_color='steelblue', width=700, height=500, scale=1, max_font_size=500, collocations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7111d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate wordcloud for the two categories\n",
    "cloud_offensive = wordcloud1.generate(offensive_sent)\n",
    "cloud_normal = wordcloud2.generate(normal_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4162e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(20,10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('300 Most Common Words in Offensive Tweets')\n",
    "plt.imshow(cloud_offensive)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('300 Most Common Words in Non-offensive Tweets')\n",
    "plt.imshow(cloud_normal)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf82c4b",
   "metadata": {},
   "source": [
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf957c58",
   "metadata": {},
   "source": [
    "- Both categories have common words like 'control', 'people', 'trump'\n",
    "- offensive words like 'shit', 'bitch' can also be seen in the offensve categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e50068",
   "metadata": {},
   "source": [
    "### Limitations of the Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee9115",
   "metadata": {},
   "source": [
    "1. The preprocesing does not handle weird symbols tha are not from the english alphabet\n",
    "2. Does not handle misspelled words\n",
    "3. Does not remove repetitive words like 'aaaaaaaaa' 'bbbb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f8073",
   "metadata": {},
   "source": [
    "## Part 2 - Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7d7aa",
   "metadata": {},
   "source": [
    "To go further in this classification task, we need to extract features and get the numerical representation of the twitter text so that it can be used by the ML & DL algorithms.\n",
    "To do this, we will try a number of feature extraction techniques:\n",
    "1. Bag of words\n",
    "2. Tf-Idf\n",
    "3. Word2vec\n",
    "4. Glove\n",
    "5. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393422d",
   "metadata": {},
   "source": [
    "Since SKlearn's BOW & Tfidf functions expect strings & not list, I will use the dataset with the joined words which I created in the visuaization above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a5b9f",
   "metadata": {},
   "source": [
    "### Feature Extraction with Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3eb82",
   "metadata": {},
   "source": [
    "#### A few notes on the Bag of Words technique \n",
    "\n",
    "- All the unique words in the dataset are collected and become the attributes\n",
    "- That is, if there are 3000 unique words in the dataset, there will be 3000 columns \n",
    "- the values in the column for each row is the frequency of the corresponding word in that row\n",
    "\n",
    "**Limitations**\n",
    "- This technique results in a very sparse matrix\n",
    "- Lots of data to process, thus requiring a lot of computing time and resources\n",
    "- Gives more weight/importance to words that are frequently occuring but may not actually have any effect on the tweet being negative e.g the word 'right' occured very frequently in offensive tweets\n",
    "- Will not be able to handle a negative word that was not in the dataset and will actually not be able to correctly classify such a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(df_copy['tweet'])\n",
    "counts=pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_bow = pd.merge(df_copy,counts,left_index =True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow.rename({'tweet_x':'tweet','label_x':'label'}, inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8be63",
   "metadata": {},
   "source": [
    "### Feature Extraction with -Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702565",
   "metadata": {},
   "source": [
    "#### A few notes on the Tf-Idf technique \n",
    "\n",
    "- All the unique words in the dataset are collected and become the attributes\n",
    "- That is, if there are 3000 unique words in the dataset, there will be 3000 columns \n",
    "- the values in the column for each row is the frequency of the corresponding word in that row (Term frequency) divided by the total occurences of the word in the whole dataset (Document frequency)\n",
    "\n",
    "**Advantages over BOW**\n",
    "- Because it uses TF/DF, it eliminates the issue of giving high important to irrelavnt frequently occuring words. Because words that occur frequently will ave a high document freq (DF) and will thus be assigned a low weight while rare words will have low DF and will be assigned higher weights\n",
    "\n",
    "**Limitations**\n",
    "- Also results in a very sparse matrix\n",
    "- Lots of data to process, thus requiring a lot of computing time and resources\n",
    "- Will not be able to handle a negative word that was not in the dataset and will actually not be able to correctly classify such a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf = tfidf_transformer.fit_transform(bow)\n",
    "tf_idf_counts = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_tfidf = pd.merge(df_copy,tf_idf_counts,left_index =True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.rename({'tweet_x':'tweet','label_x':'label'}, inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84697e5e",
   "metadata": {},
   "source": [
    "### Feature Extraction with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8377d2c",
   "metadata": {},
   "source": [
    "#### A few notes on the Word2Vec technique \n",
    "\n",
    "- This technique involves training a feed forward neural network with a single hidden layer to generate n dim vector representations for words.\n",
    "- There are 2 methods for training the neural network: Continous BOW & Skip gram\n",
    "  1. In the continous BOW, the surrounding words are used to predict the target/centre words. \n",
    "    - e.g We have a sentence: I'm going to the mall to get clothes\n",
    "    - The target word is mall, we select a window of 3 (this means that we will use the 3 words on each side of the target word to try and predict the target word.\n",
    "    - so the input to the neural network will be going, to, the, to , get clothes and the netwrok will keep training and updating the weights till it can correctly predict the target word,\n",
    "    - After training, the weights in the hidden layer will be retrieved as the n dim vector to represent the target word.\n",
    "    - so if there are 100 units in that layer, our word will be represented by an 100dim vector\n",
    "  2. In the skipgram model, the target word is used t predict the surrounding words\n",
    "    - so the input is the target word and the outputs will the 3 surrounding words on either side.\n",
    "\n",
    "**Advantages over BOW & Tf-Idf**\n",
    " - Eliminates the issue of having a sparse matrix and reduces the amount of data that needs to be processed\n",
    " - Now that we are no longer dealing with term frequency, it elimintaes the problem f just classifying based on term frequency\n",
    " - since words now have vector representations, the model will be able to detect synonyms of different negative words using cosine similarity\n",
    "\n",
    "**Limitations**\n",
    "- The word embeddings is only as good as the data used to train it. A good word2vec model needs to be trained with very huge volumes of high quality data like the google word2vec model\n",
    "- Word2vec only considers the surrounding words in a sentence( based on the window selected) and not the other sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22478c1",
   "metadata": {},
   "source": [
    "I will train a word2vec model that can be used to feed our ML algorithms. \n",
    "To train the word2vec model we need to split the data into train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6981b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df.sample(frac=0.90, random_state = 5)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df.drop(index = train_set.index)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b011b6",
   "metadata": {},
   "source": [
    "I will train the word2vec model from the genism library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnvert the tweet column to a list o lists\n",
    "train_list =  train_set['tweet'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the word2vec model\n",
    "w2v_model = Word2Vec(train_list, vector_size=150, window=5, min_count=2, workers=3)\n",
    "w2v_model.train(train_list,total_examples=11916,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30100ddf",
   "metadata": {},
   "source": [
    "Now lets test our word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c936e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"fucking\"\n",
    "w2v_model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038fce63",
   "metadata": {},
   "source": [
    "In the cell above, I tried to get the words similar to fucking, and words like play,saturday etc are similar based on the embeddings.\n",
    "This makes me conclude that the word2vec model has not been trained well because we dont have enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f87e74",
   "metadata": {},
   "source": [
    "I can use Google's pretrained word2vec model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging code taken from http://rare-technologies.com/word2vec-tutorial/\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pretrained glove model\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce878e3b",
   "metadata": {},
   "source": [
    "Now lets check out the performance of the pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"fucking\"\n",
    "word2vec_model.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ff3d3",
   "metadata": {},
   "source": [
    "Now I can see that google's pretrained model is able to get the words that are similar to target words. Because this works better, I will use this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565c960",
   "metadata": {},
   "source": [
    "#### Create aggregated sentence vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416f7be",
   "metadata": {},
   "source": [
    "Using the google word2vec model, I will create aggregated sentence vectors based on the word vectors for each word in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict of all the words in the word2vec model\n",
    "words = set(word2vec_model.index_to_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect = np.array([np.array([word2vec_model[word] for word in row if word in words]) for row in df['tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfe55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f8cfc",
   "metadata": {},
   "source": [
    "Taking a look at our sentence vector, I can see that its an array of arrays (just like a list of lists)\n",
    "The first array contains 3 arrays which is no surprise, because if we recall, the first sentence is our processed dataset has 3 words. So each of the 3 arrays we see, represents the 300dim for each word in the sentence. \n",
    "This means that the dimension of each main array would be different.\n",
    "\n",
    "If we take a look at the next main array, it also has 3 arrays. Why is this so, since our second sentence has 4 words?\n",
    "Taking a look at the 2nd sentence, the last word (Trump2020) is most likely not in google trained word 2vec.\n",
    "\n",
    "Let's test this hypothesis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60605975",
   "metadata": {},
   "outputs": [],
   "source": [
    "'trump2020' in words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc145dec",
   "metadata": {},
   "source": [
    "So, as suspected that word isnt in the pretrained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edd683",
   "metadata": {},
   "source": [
    "Now lets observe the vectors for the first 20 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(df_vect[:20]):\n",
    "    print(len(df['tweet'].iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818f6d8",
   "metadata": {},
   "source": [
    "**There is an issue here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc295bf",
   "metadata": {},
   "source": [
    "There is no consistency in each sentence vector. The first sentence has 3 features. The next one is also 3. But then the next is 17 and then its back to three and then seven... So if we tried to pass this into a machine learning model, it would throw an error because the ML model expects consistency.\n",
    "\n",
    "To solve this issue I'm going to take an element wide average for each sentence array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff29010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect_avg = []\n",
    "\n",
    "for array in df_vect:\n",
    "    if array.size:\n",
    "        df_vect_avg.append(array.mean(axis=0))\n",
    "    else:\n",
    "        df_vect_avg.append(np.zeros(300, dtype=float)) #it is possible that some sentences do not contain any words that have word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721d789",
   "metadata": {},
   "source": [
    "Now lets check if the length of our sentence vectors are consistent now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(df_vect_avg):\n",
    "    print(len(df['tweet'].iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd99ccf",
   "metadata": {},
   "source": [
    "Now we can see that all the sentences hava a consistent array size of 300. It is 300 because the google trained word2vec model has 300 dimensions of word embeddings for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create dataframe for word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v = pd.DataFrame(df_vect_avg)\n",
    "df_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c9434",
   "metadata": {},
   "source": [
    "Now we have a numerical featues for our data, 300 columns which represens the embedding vectors or each sentence, this is better (in terms of computing time & resources) than the BOW & TF-IDF models that had about 18,000 columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbcf50",
   "metadata": {},
   "source": [
    "Lets create a full dataset for our word2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_df = pd.merge(df[['tweet','label']],df_w2v,left_index =True, right_index=True)\n",
    "word2vec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c638f",
   "metadata": {},
   "source": [
    "### Feature Extraction with Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f5b20",
   "metadata": {},
   "source": [
    "#### A few notes on the Glove technique \n",
    "\n",
    "- This technique considers the context of words globally (i.e in the whole document or training data) as opposed to only local surrounding words like in the word2vec model.\n",
    "- In this technique, a word by context matrix is generated such that each distinct word is a row in the matrix and the columns represent different contexts.\n",
    "- For each word, the frequency of occurence of this word in some â€œcontextâ€ (the columns) in the whole training data is counted\n",
    "- After this, the word-context matrix is factorized to obtain the word - features matrix. \n",
    "- In the word - features matix, Each row is now the n-dim vector of each word.\n",
    "\n",
    "\n",
    "**Advantages over BOW & Tf-Idf**\n",
    " - Eliminates the issue of having a sparse matrix and reduces the amount of data that needs to be processed\n",
    " - Now that we are no longer dealing with term frequency, it elimintaes the problem f just classifying based on term frequency\n",
    " - since words now have vector representations, the model will be able to detect synonyms of different negative words using cosine similarity\n",
    "\n",
    "**Advantages over Word2vec**\n",
    "- It considers the context of each word globally and not just in the local surrounding.\n",
    "\n",
    "**Limitations**\n",
    "- The word embeddings is only as good as the data used to train it. \n",
    "- The words have the same embeddings irrespectve of the context they are used in. ELMO tries to eliminate this issue by looking at sentence before assigning an embedding based on the context the word is used in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pretrained glove model\n",
    "glove_model = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c4b27",
   "metadata": {},
   "source": [
    "Lets check out some words & their similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d11b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model['boy'], glove_model['boy'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53944cb",
   "metadata": {},
   "source": [
    "so each word is repesented by a 100 dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model.most_similar(positive='boy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85d5a6",
   "metadata": {},
   "source": [
    "As we can see, the model does a pretty good job of fetching other words that are similar to 'boy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadacb9",
   "metadata": {},
   "source": [
    "#### Visualize some word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d81a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"boy\", \"girl\", \"man\", \"woman\", \"king\", \"queen\", \"banana\", \"apple\", \"learn\", \"study\"]\n",
    "\n",
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    wordvecs = []\n",
    "\n",
    "    for word in vocab:\n",
    "        wordvecs.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    # n_components: #dimensions to reduce the data into\n",
    "    tsne_model = TSNE(perplexity=3, n_components=2, init='pca', random_state=42)\n",
    "    coordinates = tsne_model.fit_transform(wordvecs)\n",
    "\n",
    "    #Use Matplotlib Scatter plot\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in coordinates:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(8,8)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(2, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "tsne_plot(glove_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c9f41",
   "metadata": {},
   "source": [
    "The word vectors for boy,man and girl & woman are quite close but not as close as earn & study because these 2 words practically mean the same thing.  \n",
    "I will use this model to generate sentence embeddings for my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a set for all unique words in the glove model\n",
    "glove_words = set(glove_model.index_to_key )\n",
    "len(glove_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd5c4a",
   "metadata": {},
   "source": [
    "so, there are 400000 unique words in the glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glove = np.array([np.array([glove_model[word] for word in row if word in glove_words]) for row in df['tweet']])\n",
    "df_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take a look into this matrix\n",
    "df_glove[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f32e3",
   "metadata": {},
   "source": [
    "This is similar to what was observed for the word2vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(df_glove[:20]):\n",
    "    print(len(df['tweet'].iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9252d4d",
   "metadata": {},
   "source": [
    "We can see that there is also the inconsistency in size of the word vectors for each sentence, so we have to do an element wise average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glove_avg = []\n",
    "\n",
    "for array in df_glove:\n",
    "    if array.size:\n",
    "        df_glove_avg.append(array.mean(axis=0))\n",
    "    else:\n",
    "        df_glove_avg.append(np.zeros(100, dtype=float)) #it is possible that some sentences do not contain any words that have word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(df_glove_avg):\n",
    "    print(len(df['tweet'].iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae86821",
   "metadata": {},
   "source": [
    "Now we can see that all the sentences hava a consistent array size of 200. It is 200 because the  glove model (trined with twitter) has 200 dimensions of word embeddings for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets create a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce96d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df = pd.DataFrame(df_glove_avg)\n",
    "glove_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_glove_df = pd.merge(df[['tweet','label']],glove_df,left_index =True, right_index=True)\n",
    "full_glove_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89c539",
   "metadata": {},
   "source": [
    "### Feature Extraction with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c36eb",
   "metadata": {},
   "source": [
    "#### A few notes on BERT \n",
    "\n",
    "- BERT is a model which uses a stack of encoders (transformer encoder) to process words but unlike the other techniques, the training involves both left & right context. The two techniques used to train the bert model are\n",
    "- The first step towards extracting featurs with BERT is to tokenize the sentences. Each tokenized sentence will have a CLS token, the tokens of the words, SEP token (which depicts the end of each sentence) and then padding (padding is done to ensure the dimensions of al the rows are the same.\n",
    "- CLS & SEP tokens are the same for all sentences.\n",
    "- These tokenized values are then passed into a pretrained BERT model\n",
    "- For each token in a sentence, BERT outputs a hidden state (768 vals) associated with each token\n",
    "- So for our dataset that has 23 tokens for each sentence & 13240 sentences, the output of bert will be 13,240 x 23 x 768\n",
    "- For this type of classifiation task, I am only interested in the hidden state associated with the initial token [CLS], which somehow captures the semantics of the entire sentence better than the others.\n",
    "- So the feature extracted by bert will be the hidden states of just the first token for each sentence. (13240 * 768)\n",
    "\n",
    "**Advantages over Word2vec & Glove**\n",
    " - The model is trained with both left and right context\n",
    "\n",
    "**Limitations**\n",
    "- Very memory & compute heavy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')  #an object representing the device on which a torch.Tensor is or will be allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d25f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate an object of bert's pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d17fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model that is an instance of the pretrained BERTmodel and save on the device\n",
    "bert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddd4f8",
   "metadata": {},
   "source": [
    "#### Tokenize the text\n",
    "\n",
    "We already tokenized the texts n each row but this tokenizer expects a lists of sentences and not a list of lists, so we will use the df['tweet'] that has sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfdafc2",
   "metadata": {},
   "source": [
    "Before we tokenize, we have to decide what max length to use for padding. Rows with length less than this will be padded to meet the mx length whie rows more than this will be truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9928e",
   "metadata": {},
   "source": [
    "Lets look at the average length of rows in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f180e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = [len(row) for row in df['tweet']]\n",
    "plt.hist(data_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b716b",
   "metadata": {},
   "source": [
    "The histogram above shows that the only a small proportion of the data has more 23 words, so I will set max length to be 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cab3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_vals = tokenizer(df_copy['tweet'].tolist(), max_length = 23, padding = True, truncation = True, return_tensors=\"pt\")\n",
    "#The result is a dictionary with input_ids & attention mask as keys and tensors as values\n",
    "#The size of the tensor would be the no of rows in the dataset by the max padding length\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move the tokenized results to the device (CPU)\n",
    "#not sure you need this \n",
    "tokenized_vals = {k:torch.tensor(v).to(device) for k,v in tokenized_vals.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf46ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_vals['input_ids'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c053a",
   "metadata": {},
   "source": [
    "Looking at the tokenized values already, I can deduce that the CLS is 101 while the SEP is 102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558c9f0",
   "metadata": {},
   "source": [
    "Get the texts ([CLS]) hidden states by running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  hidden_text = bert_model(**tokenized_vals) #dim : [batch_size(no_sentences), tokens, embedding_dimensions]\n",
    "\n",
    "#get only the [CLS] hidden states\n",
    "cls= hidden_text.last_hidden_state[:,0,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba1473",
   "metadata": {},
   "source": [
    "**Note: I ran into memory issues when I tried to run the code above. Solved it by increasing the size of my virtual memory and running again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f021cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_text.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d700be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df= pd.DataFrame(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f353f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df_full = pd.merge(df[['tweet','label']],bert_df,left_index =True, right_index=True)\n",
    "bert_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d458bcc",
   "metadata": {},
   "source": [
    "### Part 3 - Dealing with the Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d2b32",
   "metadata": {},
   "source": [
    "Earlier in the project, I observed that the dataset was imbalanced. There are different ways to deal with this, but for this project, my approach would be:\n",
    " 1. Create two datasets for each feature extraction technique: One would be the dataset as it is and the other will be downsampled.\n",
    " 2. Split both datasets into Train (90%) and Test (10%)\n",
    " 3. To downsample the train set, I will remove records from the majority class in order to create a more balanced dataset.  I would do this to only the train set and leave the test set as it is. \n",
    " 4. Compare the performace of both the normal datasets & the downsampled one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f68e0",
   "metadata": {},
   "source": [
    "#### Create two sets of training data for each technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb2f4a",
   "metadata": {},
   "source": [
    "#### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = df_bow.sample(frac=0.9, random_state = 5)\n",
    "test_bow = df_bow.drop(index=train_bow.index)\n",
    "test_bow.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the both categories\n",
    "train_bow_offensive = train_bow[train_bow['label']==1]\n",
    "train_bow_normal = train_bow[train_bow['label']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample the normal tweets\n",
    "train_bow_normal_ds = resample(train_bow_normal, n_samples= 3925, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow_downsampled = pd.concat([train_bow_normal_ds,train_bow_offensive], ignore_index =True).sample(frac=1, random_state= 1)\n",
    "train_bow_downsampled.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6734eef",
   "metadata": {},
   "source": [
    "Now for the BOW technique, I have two different training sets: 1. train_bow & 2. train_bow_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59abe95",
   "metadata": {},
   "source": [
    "#### TF-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf = df_tfidf.sample(frac=0.9, random_state = 5)\n",
    "\n",
    "test_tf_idf = df_tfidf.drop(index=train_tf_idf.index)\n",
    "test_tf_idf.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#isolate the both categories\n",
    "train_tf_idf_offensive = train_tf_idf[train_tf_idf['label']==1]\n",
    "train_tf_idf_normal = train_tf_idf[train_tf_idf['label']==0]\n",
    "\n",
    "#Downsample the normal tweets\n",
    "train_tf_idf_normal_ds = resample(train_tf_idf_normal, n_samples= 3925, random_state = 42)\n",
    "\n",
    "#merge the offensive and the dwnsampled normal back together\n",
    "train_tf_idf_downsampled = pd.concat([train_tf_idf_normal_ds,train_tf_idf_offensive], ignore_index =True).sample(frac=1, random_state= 1)\n",
    "train_tf_idf_downsampled.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e70b9",
   "metadata": {},
   "source": [
    "Now for the Tf-Idf technique, I have two different training sets: 1. train_tf_idf & 2. train_tf_idf_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba791613",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word2vec = word2vec_df.sample(frac=0.9, random_state = 5)\n",
    "\n",
    "test_word2vec = word2vec_df.drop(index=train_word2vec.index)\n",
    "test_word2vec.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#isolate the both categories\n",
    "train_word2vec_offensive = train_word2vec[train_word2vec['label']==1]\n",
    "train_word2vec_normal = train_word2vec[train_word2vec['label']==0]\n",
    "\n",
    "#Downsample the normal tweets\n",
    "train_word2vec_normal_ds = resample(train_word2vec_normal, n_samples= 3925, random_state = 42)\n",
    "\n",
    "#merge the offensive and the dwnsampled normal back together\n",
    "train_word2vec_downsampled = pd.concat([train_word2vec_normal_ds,train_word2vec_offensive], ignore_index =True).sample(frac=1, random_state= 1)\n",
    "train_word2vec_downsampled.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcaa88d",
   "metadata": {},
   "source": [
    "Now for the Word2vec technique, I have two different training sets: 1. train_word2vec & 2. train_word2vec_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6f849",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92870d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove = full_glove_df.sample(frac=0.9, random_state = 5)\n",
    "\n",
    "test_glove = full_glove_df.drop(index=train_glove.index)\n",
    "test_glove.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#isolate the both categories\n",
    "train_glove_offensive = train_glove[train_glove['label']==1]\n",
    "train_glove_normal = train_glove[train_glove['label']==0]\n",
    "\n",
    "#Downsample the normal tweets\n",
    "train_glove_normal_ds = resample(train_glove_normal, n_samples= 3925, random_state = 42)\n",
    "\n",
    "#merge the offensive and the dwnsampled normal back together\n",
    "train_glove_downsampled = pd.concat([train_glove_normal_ds,train_glove_offensive], ignore_index =True).sample(frac=1, random_state= 1)\n",
    "train_glove_downsampled.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af5f86",
   "metadata": {},
   "source": [
    "Now for the Glove technique, I have two different training sets: 1. train_glove & 2. train_glove_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Placeholder for splitting train & test for BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2318c72",
   "metadata": {},
   "source": [
    "### Part 4 - Training & Evaluating Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e7bfb8",
   "metadata": {},
   "source": [
    "I will be training the following models for this project:\n",
    "\n",
    "    1. Naive Bayes\n",
    "    2. Logistic Regression\n",
    "    3. SVC\n",
    "    4. Decision Tree\n",
    "    5. Random Forest\n",
    "    6. Gradient Boosting\n",
    "    7. Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the models\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c191d",
   "metadata": {},
   "source": [
    "Since most of these models have different hyperparameters which have to be tuned to get good performance, I'll be training these models with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab64cb58",
   "metadata": {},
   "source": [
    "Parameters for the **multinomial naive bayes**\n",
    "- Sklearn class for this mode has a few parameters like alpha (which is the smoothing parameter) & fit_prior (whether to learn class probabilities or use a uniform one).\n",
    "- for this project, I will use the default values of these parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc20ae",
   "metadata": {},
   "source": [
    "Parameters for **Logistic Regression**\n",
    "- Sklearn has some params for this model:\n",
    "    1. penalty for regularization: default is l2\n",
    "    2. C - which is the inverse of regularization coeffiecient. So smaller values mean higher regularization.  Default is 1\n",
    "- for this project, I will use the default value for the penalty but play around with the reg param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86608244",
   "metadata": {},
   "source": [
    "Parameters for **SVC**\n",
    "- sklearn has some params for this model:\n",
    "    1. C - which is the inverse of regularization coeffiecient\n",
    "    2. Kernel \n",
    "- for this project, I will play around with different values for C & kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58afc75b",
   "metadata": {},
   "source": [
    "Parameters for **Decision Tree Classifier**\n",
    "- sklearn has some params for this model:\n",
    "    1. Criterion - which is the formula used to calculate impurity e.g Gini impurity or entropy\n",
    "    2. some other parameters which are used to prevent overfitting by pre-pruning/early stopping like:\n",
    "      - max-depth: nodes will not be split after this depth\n",
    "      - min_samples_split: This is the minimum number f samples required for a nodel to be split. If the no of samples is less than this value, the node will be made a eaf node.\n",
    "      - min_samples_leaf: This is the min of samples that should be in a leaf node. A node splitting into leafs will only be considered if it has the min_samples _leaf in each leaf. \n",
    "      - ccp-alpha: parameter used for cost complexity post pruning. The higher values of the ccp_alpha, the more odes are pruned.\n",
    "- for this project, I will play around with different values for Criterion & the other parameters for pre pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3f898",
   "metadata": {},
   "source": [
    "Parameters for **Random Forest**\n",
    "- sklearn has some params for this model, (some are similar to the decision tree model):\n",
    "    1. n_estimators - The number of trees in the forest.\n",
    "    2. Criterion - which is the formula used to calculate impurity e.g Gini impurity or entropy for each of the base estimators\n",
    "    2. some other parameters which are used to prevent overfitting by pre-pruning/early stopping like:\n",
    "      - max-depth: nodes will not be split after this depth\n",
    "      - min_samples_split: This is the minimum number of samples required for a nodel to be split. If the no of samples is less than this value, the node will be made a eaf node.\n",
    "      - min_samples_leaf: This is the min of samples that should be in a leaf node. A node splitting into leafs will only be considered if it has the min_samples _leaf in each leaf. \n",
    "      - ccp-alpha: parameter used for cost complexity post pruning. The higher values of the ccp_alpha, the more odes are pruned.\n",
    "      - max-features: the no of max features to consider when looking for split nodes\n",
    "        - max_samples: the number of samples to draw to train each base estimator\n",
    "- for this project, I will play around with different values n_estimators, criterion etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90c74e",
   "metadata": {},
   "source": [
    "Parameters for **Adaboost**\n",
    "- sklearn has some params for this model:\n",
    "    1. Estimator - usually a decision tree\n",
    "    2. n_estimators - The number of base estimators to use\n",
    "    3. learning_rate - Weight assigned to each estimator at each boosting iteration\n",
    "- for this project, I will play around with different values n_estimators, criterion etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d342f9",
   "metadata": {},
   "source": [
    "Parameters for **Gradient Boosting**\n",
    "- sklearn has some params for this model, (some are similar to the decision tree model):\n",
    "    1. loss - the loss function to be optimized.\n",
    "    2. learning_rate - Weight assigned to each estimator at each boosting iteration\n",
    "    3. n_estimators - The number of base estimators to use\n",
    "    4. Criterion: The loss function used to find the optimal feature and threshold to split the data\n",
    "    5. max_depth: the maximum depth of each tree\n",
    "    6. init: the initial estimator. By default, it is the log(odds) converted to a probability(like we discussed before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff7241",
   "metadata": {},
   "source": [
    "Now that I have defined all the models that I will be using in this project, its time to start training and evaluating them with the different training sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5dcc8",
   "metadata": {},
   "source": [
    "### Training Models with BOW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ab969",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e847e0e",
   "metadata": {},
   "source": [
    "####  - Imbalanced BOW train set with Naive bayes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a74e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_labels_nb_bow = nb_model.predict(test_bow.iloc[:,2:])\n",
    "nb_bow_f1score = f1_score(test_bow['label'], pred_labels_nb_bow, average = 'macro')\n",
    "nb_bow_cm = confusion_matrix(test_bow['label'], pred_labels_nb_bow)\n",
    "per_class = nb_bow_cm.diagonal()/nb_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_nb_result = pd.Series({'Model Name': 'Naive Bayes' , 'Dataset':'Bow_Imbalanced', 'Macro_F1score':nb_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=nb_bow_cm, display_labels=nb_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_nb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb462da",
   "metadata": {},
   "source": [
    "#### Evaluating Results of Imbalanced BOW Training with Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e14001",
   "metadata": {},
   "source": [
    "In the results shown above, the macro F1score for the model is about 0.7. However, the model does a better job of predicting the majority class (83% accuracy) than it does with predicting the minority class (56%).\n",
    "This might be because the model is biased towards the majority class and this is one of the issues with training a model with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289e248",
   "metadata": {},
   "source": [
    "#### Balanced BOW train set with Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model2 = MultinomialNB()\n",
    "nb_model2.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_labels_nb_bow = nb_model2.predict(test_bow.iloc[:,2:])\n",
    "nb_bow_f1score = f1_score(test_bow['label'], pred_labels_nb_bow, average = 'macro')\n",
    "nb_bow_cm = confusion_matrix(test_bow['label'], pred_labels_nb_bow)\n",
    "per_class = nb_bow_cm.diagonal()/nb_bow_cm.sum(axis=1)\n",
    "bow_balanced_nb_result = pd.Series({'Model Name': 'Naive Bayes' , 'Dataset':'Bow_balanced','Macro_F1score':nb_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=nb_bow_cm, display_labels=nb_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_nb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9551f30",
   "metadata": {},
   "source": [
    "For some eason, the performance is even worse and the model now seemed to be biased towards the minority class.\n",
    "\n",
    "But WHY??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553e005",
   "metadata": {},
   "source": [
    "####  BOW with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff4366",
   "metadata": {},
   "source": [
    "For logistic regression, I will try different values for regularization parameter, C, the maximum iteration & the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9894669",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_parameters = {'C':[1, 10, 20], 'max_iter':[100,150], 'solver':['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e23da",
   "metadata": {},
   "source": [
    "#### Imbalanced Bow w/ Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68a71d",
   "metadata": {},
   "source": [
    "**Search for the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_im = LogisticRegression()\n",
    "clf = GridSearchCV(logit_im, log_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "clf.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "\n",
    "grid_results_log_im = pd.DataFrame(clf.cv_results_)\n",
    "grid_results_log_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc18b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_log_im.sort_values(by= 'rank_test_score')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89542d3f",
   "metadata": {},
   "source": [
    "The set of params {'C': 10, 'max_iter': 150, 'solver': 'lbfgs'}, gave the best result during both training and validation. \n",
    "However:\n",
    "    1. The training score of about 97% is way more than the test score of about 71%. There is a high chance the model is overfitting, beause it has a lower reg coefficient and also more iterations.\n",
    "    2. It also had a mean fit time of about 35secs.\n",
    "    \n",
    "Because of the above, I would select the 4th row, with {'C': 1, 'max_iter': 100, 'solver': 'liblinear'} as the 'best' because although it has slightly lower test score, the train score is 90%, so train & test scores are closer than the one above.\n",
    "It also has a mean test time of 8.8 seconds which is about a quarter of the top ranked option.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9620829",
   "metadata": {},
   "source": [
    "But let's see what gridsearch cv selects as the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a1d33",
   "metadata": {},
   "source": [
    "As expected, the top ranked is the best result. But I will train the imbalanced dataset with the 4th option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da237c",
   "metadata": {},
   "source": [
    "**Train the Imbalanced dataset with the params I have chosen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(C = 1.0, solver = 'liblinear', max_iter = 100)\n",
    "log_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_log_im = log_model.predict(test_bow.iloc[:,2:])\n",
    "log_bow_f1score = f1_score(test_bow['label'], pred_log_im, average = 'macro')\n",
    "log_bow_cm = confusion_matrix(test_bow['label'], pred_log_im)\n",
    "per_class = log_bow_cm.diagonal()/log_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_log_result = pd.Series({'Model Name': 'Logistic Regression' , 'Dataset':'Bow_Imbalanced','Macro_F1score':log_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=log_bow_cm, display_labels=log_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_log_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23a662",
   "metadata": {},
   "source": [
    "This model does better on predicting the imbalanced dataset than the NB model. Athough the difference between the two class accuracy is a los"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6f552",
   "metadata": {},
   "source": [
    "**Balanced + Logit + BOW**\n",
    "\n",
    "Search for best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_bal = LogisticRegression()\n",
    "clf2 = GridSearchCV(logit_bal, log_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "clf2.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "\n",
    "grid_results_log_bal = pd.DataFrame(clf2.cv_results_)\n",
    "grid_results_log_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83929b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_log_bal.sort_values(by = 'rank_test_score')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b2e5c2",
   "metadata": {},
   "source": [
    "from gridsearch, I'll select: {'C': 10, 'max_iter': 150, 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(C = 10, solver = 'liblinear', max_iter = 150)\n",
    "log_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_log_bal = log_model.predict(test_bow.iloc[:,2:])\n",
    "log_bow_f1score = f1_score(test_bow['label'], pred_log_bal, average = 'macro')\n",
    "log_bow_cm = confusion_matrix(test_bow['label'], pred_log_bal)\n",
    "per_class = log_bow_cm.diagonal()/log_bow_cm.sum(axis=1)\n",
    "bow_balanced_log_result = pd.Series({'Model Name': 'Logistic Regression' , 'Dataset':'Bow_balanced','Macro_F1score':log_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=log_bow_cm, display_labels=log_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_log_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e1dda",
   "metadata": {},
   "source": [
    "The undersampling increased the accuracy for the minorty class but also reduced the accuracy of the majority and the overall performance of the model. But now, we can see that the model can now give an almost equal performance for both classes, so there is no longer bias here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29d327",
   "metadata": {},
   "source": [
    "####  BOW with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_parameters = {'C':[0.1,0.5,1,5,10]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775859d3",
   "metadata": {},
   "source": [
    "Imbalanced data - Search for the best params m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a4b5f",
   "metadata": {},
   "source": [
    "** Running gridsearch for SVC took a very very long time!!! Find out why!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286774b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC()\n",
    "search = GridSearchCV(svc_model, svc_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7db0b",
   "metadata": {},
   "source": [
    "Use the best param to train the model with the imbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC(C=0.1)\n",
    "svc_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_svc_im = svc_model.predict(test_bow.iloc[:,2:])\n",
    "svc_bow_f1score = f1_score(test_bow['label'], pred_svc_im, average = 'macro')\n",
    "svc_bow_cm = confusion_matrix(test_bow['label'], pred_svc_im)\n",
    "per_class = svc_bow_cm.diagonal()/svc_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_svc_result = pd.Series({'Model Name':'SVC', 'Dataset': 'BOW_Imbalanced','Macro_F1score':svc_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=svc_bow_cm, display_labels=log_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_svc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaff5cf",
   "metadata": {},
   "source": [
    "**SVC + BOW + Balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3130bc3",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bede996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC()\n",
    "search = GridSearchCV(svc_model, svc_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model =LinearSVC(C=0.1)\n",
    "svc_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_svc_bal = svc_model.predict(test_bow.iloc[:,2:])\n",
    "svc_bow_f1score = f1_score(test_bow['label'], pred_svc_bal, average = 'macro')\n",
    "svc_bow_cm = confusion_matrix(test_bow['label'], pred_svc_bal)\n",
    "per_class = svc_bow_cm.diagonal()/svc_bow_cm.sum(axis=1)\n",
    "bow_balanced_svc_result = pd.Series({'Model Name':'SVC', 'Dataset': 'BOW_balanced','Macro_F1score':svc_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=svc_bow_cm, display_labels=svc_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_svc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d26dc",
   "metadata": {},
   "source": [
    "**Decision Tree + BOW + Imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dee902",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_parameters = {'criterion':['gini'], 'min_samples_split':[20,30], 'min_samples_leaf': [2,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_im = DecisionTreeClassifier()\n",
    "search = GridSearchCV(tree_im, tree_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(criterion= 'gini', min_samples_leaf=5, min_samples_split=30)\n",
    "tree_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_tree_bal = tree_model.predict(test_bow.iloc[:,2:])\n",
    "tree_bow_f1score = f1_score(test_bow['label'], pred_tree_bal, average = 'macro')\n",
    "tree_bow_cm = confusion_matrix(test_bow['label'], pred_tree_bal)\n",
    "per_class = tree_bow_cm.diagonal()/tree_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_tree_result = pd.Series({'Model Name':'Decision Tree', 'Dataset': 'BOW_Imbalanced','Macro_F1score':tree_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=tree_bow_cm, display_labels=tree_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_tree_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814bec5",
   "metadata": {},
   "source": [
    "**Decision Tree + BOW + Balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da59b2c",
   "metadata": {},
   "source": [
    "Param search for the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_im = DecisionTreeClassifier()\n",
    "search = GridSearchCV(tree_im, tree_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2126aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(criterion= 'gini', min_samples_leaf=2, min_samples_split=20)\n",
    "tree_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_tree_bal = tree_model.predict(test_bow.iloc[:,2:])\n",
    "tree_bow_f1score = f1_score(test_bow['label'], pred_tree_bal, average = 'macro')\n",
    "tree_bow_cm = confusion_matrix(test_bow['label'], pred_tree_bal)\n",
    "per_class = tree_bow_cm.diagonal()/tree_bow_cm.sum(axis=1)\n",
    "bow_balanced_tree_result = pd.Series({'Model Name':'Decision Tree', 'Dataset': 'BOW_balanced','Macro_F1score':tree_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=tree_bow_cm, display_labels=tree_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_tree_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd502c6f",
   "metadata": {},
   "source": [
    "**Random Forest + BOW + Imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a357f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_forest_imbal = forest_model.predict(test_bow.iloc[:,2:])\n",
    "forest_bow_f1score = f1_score(test_bow['label'], pred_forest_imbal, average = 'macro')\n",
    "forest_bow_cm = confusion_matrix(test_bow['label'], pred_forest_imbal)\n",
    "per_class = forest_bow_cm.diagonal()/forest_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_forest_result = pd.Series({'Model Name':'Random Forest', 'Dataset': 'BOW_Imbalanced','Macro_F1score':forest_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=forest_bow_cm, display_labels=forest_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_forest_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c6bc0",
   "metadata": {},
   "source": [
    "**Random Forest + BOW + Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_forest_bal = forest_model.predict(test_bow.iloc[:,2:])\n",
    "forest_bow_f1score = f1_score(test_bow['label'], pred_forest_bal, average = 'macro')\n",
    "forest_bow_cm = confusion_matrix(test_bow['label'], pred_forest_bal)\n",
    "per_class = forest_bow_cm.diagonal()/forest_bow_cm.sum(axis=1)\n",
    "bow_balanced_forest_result = pd.Series({'Model Name':'Random Forest', 'Dataset': 'BOW_balanced','Macro_F1score':forest_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=forest_bow_cm, display_labels=forest_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_forest_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211ec50",
   "metadata": {},
   "source": [
    "**Adaboost + BOW + ImBalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c51936",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_adaboost_imbal = adaboost_model.predict(test_bow.iloc[:,2:])\n",
    "adaboost_bow_f1score = f1_score(test_bow['label'], pred_adaboost_imbal, average = 'macro')\n",
    "adaboost_bow_cm = confusion_matrix(test_bow['label'], pred_adaboost_imbal)\n",
    "per_class = adaboost_bow_cm.diagonal()/adaboost_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_adaboost_result = pd.Series({'Model Name':'Adaboost', 'Dataset': 'BOW_Imbalanced','Macro_F1score':adaboost_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=adaboost_bow_cm, display_labels=adaboost_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_adaboost_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b528d19",
   "metadata": {},
   "source": [
    "**Adaboost + BOW + Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_adaboost_bal = adaboost_model.predict(test_bow.iloc[:,2:])\n",
    "adaboost_bow_f1score = f1_score(test_bow['label'], pred_adaboost_bal, average = 'macro')\n",
    "adaboost_bow_cm = confusion_matrix(test_bow['label'], pred_adaboost_bal)\n",
    "per_class = adaboost_bow_cm.diagonal()/adaboost_bow_cm.sum(axis=1)\n",
    "bow_balanced_adaboost_result = pd.Series({'Model Name':'Adaboost', 'Dataset': 'BOW_balanced','Macro_F1score':adaboost_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=adaboost_bow_cm, display_labels=adaboost_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_adaboost_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a406e",
   "metadata": {},
   "source": [
    "**GBM + BOW + ImBalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_gbm_imbal = gbm_model.predict(test_bow.iloc[:,2:])\n",
    "gbm_bow_f1score = f1_score(test_bow['label'], pred_gbm_imbal, average = 'macro')\n",
    "gbm_bow_cm = confusion_matrix(test_bow['label'], pred_gbm_imbal)\n",
    "per_class = gbm_bow_cm.diagonal()/gbm_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'BOW_Imbalanced','Macro_F1score':gbm_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=gbm_bow_cm, display_labels=gbm_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_gbm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eedce6",
   "metadata": {},
   "source": [
    "**GBM + BOW + Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469779a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(train_bow_downsampled.iloc[:,2:], train_bow_downsampled['label'])\n",
    "pred_gbm_bal = gbm_model.predict(test_bow.iloc[:,2:])\n",
    "gbm_bow_f1score = f1_score(test_bow['label'], pred_gbm_bal, average = 'macro')\n",
    "gbm_bow_cm = confusion_matrix(test_bow['label'], pred_gbm_bal)\n",
    "per_class = gbm_bow_cm.diagonal()/gbm_bow_cm.sum(axis=1)\n",
    "bow_balanced_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'BOW_balanced','Macro_F1score':gbm_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=gbm_bow_cm, display_labels=gbm_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_balanced_gbm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e12c9",
   "metadata": {},
   "source": [
    "Now lets create a dataframe to show how the different datasets performed on the BOW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_results = pd.concat([bow_imbalanced_nb_result,bow_balanced_nb_result,bow_imbalanced_log_result, bow_balanced_log_result, bow_imbalanced_svc_result, bow_balanced_svc_result, bow_imbalanced_tree_result, bow_balanced_tree_result,bow_imbalanced_forest_result,bow_balanced_forest_result,bow_imbalanced_adaboost_result,bow_balanced_adaboost_result,bow_imbalanced_gbm_result,bow_balanced_gbm_result], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d28be",
   "metadata": {},
   "source": [
    "### Evaluating Results of Classification Models trained with BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903b0d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BOW_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f451a83",
   "metadata": {},
   "source": [
    "**Imbalanced Data**\n",
    " - The results of all the models trained with imbalanced data showed the same pattern. The accuracy of classification for the majority class was signiicantly higher than that of the minority class.\n",
    " - This proves that there is risk of having a biased model when the model is trained with Imbalanced data.\n",
    " \n",
    "**Balanced Data**\n",
    " - After training the models with balanced data, the performance of the models on each class were very comparable for most of the models except the Naive Bayes model which became biased towards the minority class after undersampling\n",
    " - The general performance of the imbalanced data was better than that of the balanced data. This might be because there were more data points in the imbalanced dataset, adding more data to the balanced dataset might help\n",
    " \n",
    "**General Model Performance**\n",
    " - Overall, the performance was that not so good. Using more advanced feature extraction techniques may improve this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2564793",
   "metadata": {},
   "source": [
    "### Training Models with Word2Vec Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306f392",
   "metadata": {},
   "source": [
    "**Imbalanced word2vec + Word2vec + Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f626c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "nb_imbal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_imbal_nb_result = pd.Series({'Model Name':'Gaussian Naive Bayes', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':nb_imbal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_imbal_nb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230eb18",
   "metadata": {},
   "source": [
    "**Balanced word2vec + Word2vec + Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "nb_bal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_bal_nb_result = pd.Series({'Model Name':'Gaussian Naive Bayes', 'Dataset': 'Word2Vec_balanced','Macro_F1score':nb_bal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_bal_nb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76e750",
   "metadata": {},
   "source": [
    "**Imbalanced word2vec + Logisic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574dc275",
   "metadata": {},
   "source": [
    "Search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_parameters = {'C':[0.1,1, 10], 'max_iter':[100,150], 'solver':['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "search = GridSearchCV(logit, log_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a95dc4ef",
   "metadata": {},
   "source": [
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c89b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "log_imbal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_imbal_log_result = pd.Series({'Model Name':'Logistic Regression', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':log_imbal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_imbal_log_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59af0d3",
   "metadata": {},
   "source": [
    "Search for the best parameters for the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "search = GridSearchCV(logit, log_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ce5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1, max_iter=100, solver='liblinear')\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "log_bal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_bal_log_result = pd.Series({'Model Name':'Logistic Regression', 'Dataset': 'Word2Vec_balanced','Macro_F1score':log_bal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_bal_log_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd2e3",
   "metadata": {},
   "source": [
    "**LinearSVC + Word2Vec Imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb311a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_parameters = {'C':[0.05,0.1,0.5,1,5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e649a8",
   "metadata": {},
   "source": [
    "Search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb652d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC()\n",
    "search = GridSearchCV(svc_model, svc_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.05)\n",
    "model.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "svc_imbal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_imbal_svc_result = pd.Series({'Model Name':'LinearSVC', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':svc_imbal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_imbal_svc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e305bc0",
   "metadata": {},
   "source": [
    "**LinearSVC + Word2Vec Balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38e494",
   "metadata": {},
   "source": [
    "Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC()\n",
    "search = GridSearchCV(svc_model, svc_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.05)\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "svc_bal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_bal_svc_result = pd.Series({'Model Name':'LinearSVC', 'Dataset': 'Word2Vec_balanced','Macro_F1score':svc_bal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_bal_svc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576b147",
   "metadata": {},
   "source": [
    "**DecisionTree + Word2Vec Imbalanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439c3fa",
   "metadata": {},
   "source": [
    "Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_parameters = {'min_samples_split':[10,20,30], 'min_samples_leaf': [2,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "search = GridSearchCV(tree_model, tree_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e83c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=10)\n",
    "model.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "tree_imbal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_imbal_tree_result = pd.Series({'Model Name':'Decision Tree', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':tree_imbal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_imbal_tree_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e434c8",
   "metadata": {},
   "source": [
    "**Decision Tree + Word2vec Balanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df260a55",
   "metadata": {},
   "source": [
    "Search for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "search = GridSearchCV(tree_model, tree_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=10)\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "tree_bal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_bal_tree_result = pd.Series({'Model Name':'Decision Tree', 'Dataset': 'Word2Vec_balanced','Macro_F1score':tree_bal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_bal_tree_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797adfa",
   "metadata": {},
   "source": [
    "**RandomForest + Word2Vec Imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train_word2vec.iloc[:,2:],train_word2vec['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "forest_imbal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_imbal_forest_result = pd.Series({'Model Name':'Random Forest', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':forest_imbal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_imbal_forest_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d645b",
   "metadata": {},
   "source": [
    "**RandomForest + Word2Vec Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b89bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "forest_bal_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_bal_forest_result = pd.Series({'Model Name':'Random Forest', 'Dataset': 'Word2Vec_Imbalanced','Macro_F1score':forest_bal_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_bal_forest_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a59681",
   "metadata": {},
   "source": [
    "**Adaboost + Word2Vec Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df48728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "adaboost_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_adaboost_result = pd.Series({'Model Name':'AdaBoost', 'Dataset': 'Word2Vec_balanced','Macro_F1score':adaboost_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_adaboost_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870edd67",
   "metadata": {},
   "source": [
    "**GBM + Word2Vec Balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "gbm_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'Word2Vec_balanced','Macro_F1score':gbm_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_gbm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16340362",
   "metadata": {},
   "source": [
    "### Evaluating Performance of Models Trained on Word2vec Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2v_results = pd.concat([w2v_imbal_nb_result, w2v_bal_nb_result, w2v_imbal_log_result, w2v_bal_log_result, w2v_imbal_svc_result, w2v_bal_svc_result, w2v_imbal_tree_result, w2v_bal_tree_result, w2v_imbal_forest_result, w2v_bal_forest_result, w2v_adaboost_result, w2v_gbm_result], axis =1)\n",
    "W2v_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530bc89",
   "metadata": {},
   "source": [
    "**How did the models perform compared to BOW?**\n",
    " - Generally, it seems like other models like NB, Logit, LinearSVC had a better performance with BOW. NOT SURE WHY\n",
    " - But the the Ensemble methods, which seemed to perform worse with BOW actually had better performance with the word2Vec\n",
    " - This proves the idea behind boosting & bagging.\n",
    " \n",
    "**What model had the best performance?**\n",
    " - Overall, I think the GMB model had the best performance, because not only did it have one of the high f1 scores, it also gave a very good minority class accuracy, which is very important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdf51c",
   "metadata": {},
   "source": [
    "#### Can I improve the GBM model further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_parameters = {'min_samples_split':[2,5,10], 'min_samples_leaf': [1,2,5], 'max_features': ['sqrt', 50,100,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6530d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "search = GridSearchCV(gbm, gbm_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e87cfb",
   "metadata": {},
   "source": [
    "#### Train & Test the GMB model with the top set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df38e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(max_features ='sqrt', min_samples_leaf = 2, min_samples_split=10)\n",
    "model.fit(train_word2vec_downsampled.iloc[:,2:],train_word2vec_downsampled['label'])\n",
    "predictions = model.predict(test_word2vec.iloc[:,2:])\n",
    "gbm_score = f1_score(test_word2vec['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_word2vec['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "w2v_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'Word2Vec_balanced','Macro_F1score':gbm_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "w2v_gbm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673899ad",
   "metadata": {},
   "source": [
    "### Training Models with Glove Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12917c",
   "metadata": {},
   "source": [
    "**Glove + Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "nb_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_nb_result = pd.Series({'Model Name':'Gaussian Naive Bayes', 'Dataset': 'Glove','Macro_F1score':nb_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_nb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb500b4",
   "metadata": {},
   "source": [
    "**Glove + Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_parameters = {'C':[0.1,0.5,1, 10], 'max_iter':[100,150], 'solver':['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "search = GridSearchCV(logit, log_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d381f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=10, max_iter = 100, solver = 'liblinear')\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "log_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_log_result = pd.Series({'Model Name':'Logistic Regression', 'Dataset': 'Glove','Macro_F1score':log_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_log_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20a204",
   "metadata": {},
   "source": [
    "**Glove + LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {'C':[0.05,0.1,0.5,1,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "search = GridSearchCV(logit, svc_params, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=5)\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "svc_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_svc_result = pd.Series({'Model Name':'Linear SVC', 'Dataset': 'Glove','Macro_F1score':nb_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_svc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d3c12",
   "metadata": {},
   "source": [
    "**Glove + DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_parameters = {'min_samples_split':[10,20,30], 'min_samples_leaf': [2,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4811ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "search = GridSearchCV(tree_model, tree_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(min_samples_split=10, min_samples_leaf=2)\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "tree_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_tree_result = pd.Series({'Model Name':'Decision Tree', 'Dataset': 'Glove','Macro_F1score':tree_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_tree_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b3e82",
   "metadata": {},
   "source": [
    "**Glove + RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "forest_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_forest_result = pd.Series({'Model Name':'Random Forest', 'Dataset': 'Glove','Macro_F1score':forest_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_forest_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b5adc",
   "metadata": {},
   "source": [
    "**Glove + Adaboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45448af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "adaboost_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_adaboost_result = pd.Series({'Model Name':'Adaboost', 'Dataset': 'Glove','Macro_F1score':adaboost_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_adaboost_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853fb6a",
   "metadata": {},
   "source": [
    "**Glove + GBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271914fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "gbm_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'Glove','Macro_F1score':gbm_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_gbm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35356a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_results = pd.concat([glove_nb_result, glove_log_result, glove_svc_result, glove_tree_result, glove_forest_result, glove_adaboost_result, glove_gbm_result], axis =1)\n",
    "glove_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2638aac",
   "metadata": {},
   "source": [
    "Generally, the models trained on glove features have a poor performance. Since GBM model had the highest sore, lets see if I can mprove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84271a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_parameters = {'min_samples_split':[2,5,10,20], 'min_samples_leaf': [1,2,5], 'max_features': ['sqrt', 50,100,200]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "search = GridSearchCV(gbm, gbm_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(max_features = 8, min_samples_leaf=1, min_samples_split=2)\n",
    "model.fit(train_glove_downsampled.iloc[:,2:],train_glove_downsampled['label'])\n",
    "predictions = model.predict(test_glove.iloc[:,2:])\n",
    "gbm_score = f1_score(test_glove['label'], predictions, average = 'macro')\n",
    "cm = confusion_matrix(test_glove['label'], predictions)\n",
    "per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "glove_gbm_result = pd.Series({'Model Name':'GBM', 'Dataset': 'Glove','Macro_F1score':gbm_score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "glove_gbm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e259d",
   "metadata": {},
   "source": [
    "Save features to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49acb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow_downsampled.to_csv('bow_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe77ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow.to_csv('bow_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word2vec_downsampled.to_csv('w2v_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d013663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word2vec.to_csv('w2v_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove_downsampled.to_csv('glove_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_glove.to_csv('glove_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow.to_csv('bow_train_im.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word2vec.to_csv('w2v_train_im.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ca800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove.to_csv('glove_train_im.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c3daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "search = GridSearchCV(gbm, gbm_parameters, scoring = 'f1_macro', return_train_score=True)\n",
    "search.fit(train_glove.iloc[:,2:],train_glove['label'])\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4756013",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use class weights to improve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c192d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:2.982355149543236, 1: 6.071847133757961 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfea968",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(C = 1.0, solver = 'liblinear', max_iter = 100, class_weight = class_weights)\n",
    "log_model.fit(train_bow.iloc[:,2:], train_bow['label'])\n",
    "pred_log_im = log_model.predict(test_bow.iloc[:,2:])\n",
    "log_bow_f1score = f1_score(test_bow['label'], pred_log_im, average = 'macro')\n",
    "log_bow_cm = confusion_matrix(test_bow['label'], pred_log_im)\n",
    "per_class = log_bow_cm.diagonal()/log_bow_cm.sum(axis=1)\n",
    "bow_imbalanced_log_result = pd.Series({'Model Name': 'Logistic Regression' , 'Dataset':'Bow_Imbalanced','Macro_F1score':log_bow_f1score, 'Majority_Class_Accuracy': per_class[0], 'Minority_Class_Accuracy': per_class[1]})\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=log_bow_cm, display_labels=log_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "bow_imbalanced_log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0451741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f13d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01e1f020b8ba44c586cbca2b8f870546": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "021dbd53f16f4a759aa34834c4842b9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ceec89ce67ca4aebbfc8e0a9915d70d5",
       "style": "IPY_MODEL_dc8e267d555347b1901e89cc01594ae1",
       "value": " 268M/268M [02:22&lt;00:00, 2.47MB/s]"
      }
     },
     "0243f7eac6f449a297e084bcb568dc80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_1a3ec461d6764cc1916e7715b1ae655a",
       "max": 267967963,
       "style": "IPY_MODEL_b2e3b881b6b34fd9a119d24f7c1a3c34",
       "value": 267967963
      }
     },
     "0369ae3cf602408eaa11e26314d447fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_56354ce427524ac597bb798eb18a7247",
       "style": "IPY_MODEL_01e1f020b8ba44c586cbca2b8f870546",
       "value": "Downloading: 100%"
      }
     },
     "06cb29e8fb5d441fb860b5a3be849ad0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "097f6ff76253465b83825770204d5538": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12fe388b7f804135ad73c37ff6f7270f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_097f6ff76253465b83825770204d5538",
       "style": "IPY_MODEL_4ad6a841a7a4413384d6e8a92d3715fa",
       "value": "Downloading: 100%"
      }
     },
     "13139ea72ab84fcb8b1ef4a386f3e343": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1662bdcb5d5f4985a42bdce39c181696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4edbc13a84e04d40b685ca118dba6796",
        "IPY_MODEL_c972521cdac944769ef6efc54ce8374b",
        "IPY_MODEL_6dee46548cac41a1b5ace5b37299775f"
       ],
       "layout": "IPY_MODEL_af5590d9c2664d788a9e3d1ae75bf0e3"
      }
     },
     "1a3ec461d6764cc1916e7715b1ae655a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "245ec7b5d6564440a068a928e7d2e26b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2bcce49239d246dc9710b0d2c3bffa62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e59f3b28a964bcc8bf38c94a675dcb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "30134dee0cc944d0b69c6f48138b5111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2e59f3b28a964bcc8bf38c94a675dcb2",
       "max": 483,
       "style": "IPY_MODEL_56720b3fc16f491b899ba45ff862c9ca",
       "value": 483
      }
     },
     "393bbc1094e84b1eb3e20a306ee8a198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a118b5fbccc43fa89164c842922c6b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43721e5a1e654751830cbb2399801797": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f605c9e6ec8343e5b57acacadfbf67a9",
        "IPY_MODEL_9c5e7f173f8948a4886c6b377ce82fb2",
        "IPY_MODEL_74a255ef3bb5477181cbbe64bdcb7d41"
       ],
       "layout": "IPY_MODEL_a51df3d9a20f4689934f2f58e7667c82"
      }
     },
     "45d58c02bbcc4603a2bffee5f3710234": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_54b90da56218409895a413e55bbb7438",
       "style": "IPY_MODEL_577587bb5dca401a8cbce8f184c5bfb0",
       "value": "Downloading: 100%"
      }
     },
     "473fee1d923b4bf4a5b7f9c19efc23e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4ad6a841a7a4413384d6e8a92d3715fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4edbc13a84e04d40b685ca118dba6796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_393bbc1094e84b1eb3e20a306ee8a198",
       "style": "IPY_MODEL_fa5acb8d1122420c83139d9abf0db9c2",
       "value": "Downloading: 100%"
      }
     },
     "54b90da56218409895a413e55bbb7438": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "56354ce427524ac597bb798eb18a7247": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "56720b3fc16f491b899ba45ff862c9ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "577587bb5dca401a8cbce8f184c5bfb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "68465d040b4f453fa1a0ca3222bad413": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f6848e22ffbd4d6faac2d99793379955",
       "style": "IPY_MODEL_a3b84e57cbb043ddba511391bff884f7",
       "value": " 483/483 [00:00&lt;00:00, 15.3kB/s]"
      }
     },
     "6dee46548cac41a1b5ace5b37299775f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d79b6b67765c4120a2fd596684761bd6",
       "style": "IPY_MODEL_70bf7e0e08694d55807375dd244b32d5",
       "value": " 466k/466k [00:00&lt;00:00, 694kB/s]"
      }
     },
     "7040e1eeeca54e968c06fdb62feea52e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "70bf7e0e08694d55807375dd244b32d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "74a255ef3bb5477181cbbe64bdcb7d41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c7789e3fbaee4bdba884f13c85b1c4c1",
       "style": "IPY_MODEL_13139ea72ab84fcb8b1ef4a386f3e343",
       "value": " 232k/232k [00:00&lt;00:00, 1.14MB/s]"
      }
     },
     "80eac12ec4794a538cdc85676d3cace9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0369ae3cf602408eaa11e26314d447fd",
        "IPY_MODEL_e7e6f8770e6d42868cd949ce465fc2f6",
        "IPY_MODEL_ffe4f90f95514029972b940e570eab0d"
       ],
       "layout": "IPY_MODEL_c2d2009887964d568df6decf662cd412"
      }
     },
     "889f7f3b7d6e4e49bb81a7b6b90dfd36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c5e7f173f8948a4886c6b377ce82fb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_da49a4102e614da8ace612ebe65cdeac",
       "max": 231508,
       "style": "IPY_MODEL_c45b5084a3284014be1b6f5ccb80313d",
       "value": 231508
      }
     },
     "a1f3eb4ad5e043918e8b519a32072a0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a3b84e57cbb043ddba511391bff884f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a51df3d9a20f4689934f2f58e7667c82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af5590d9c2664d788a9e3d1ae75bf0e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b2e3b881b6b34fd9a119d24f7c1a3c34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c2d2009887964d568df6decf662cd412": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c32ad30d2a524bed9347439df63faa6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c45b5084a3284014be1b6f5ccb80313d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c7789e3fbaee4bdba884f13c85b1c4c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c972521cdac944769ef6efc54ce8374b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_889f7f3b7d6e4e49bb81a7b6b90dfd36",
       "max": 466062,
       "style": "IPY_MODEL_245ec7b5d6564440a068a928e7d2e26b",
       "value": 466062
      }
     },
     "ceec89ce67ca4aebbfc8e0a9915d70d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfe766ccbc5b43d88beaa077d4fea620": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_12fe388b7f804135ad73c37ff6f7270f",
        "IPY_MODEL_0243f7eac6f449a297e084bcb568dc80",
        "IPY_MODEL_021dbd53f16f4a759aa34834c4842b9d"
       ],
       "layout": "IPY_MODEL_7040e1eeeca54e968c06fdb62feea52e"
      }
     },
     "d79b6b67765c4120a2fd596684761bd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d905da5b7fb845279f8993d4496a7ff2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_45d58c02bbcc4603a2bffee5f3710234",
        "IPY_MODEL_30134dee0cc944d0b69c6f48138b5111",
        "IPY_MODEL_68465d040b4f453fa1a0ca3222bad413"
       ],
       "layout": "IPY_MODEL_c32ad30d2a524bed9347439df63faa6d"
      }
     },
     "da49a4102e614da8ace612ebe65cdeac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dacd3ff93bea4e99b7b9c3119d94828f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dc8e267d555347b1901e89cc01594ae1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e7e6f8770e6d42868cd949ce465fc2f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2bcce49239d246dc9710b0d2c3bffa62",
       "max": 28,
       "style": "IPY_MODEL_473fee1d923b4bf4a5b7f9c19efc23e0",
       "value": 28
      }
     },
     "f605c9e6ec8343e5b57acacadfbf67a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_06cb29e8fb5d441fb860b5a3be849ad0",
       "style": "IPY_MODEL_dacd3ff93bea4e99b7b9c3119d94828f",
       "value": "Downloading: 100%"
      }
     },
     "f6848e22ffbd4d6faac2d99793379955": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa5acb8d1122420c83139d9abf0db9c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ffe4f90f95514029972b940e570eab0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3a118b5fbccc43fa89164c842922c6b6",
       "style": "IPY_MODEL_a1f3eb4ad5e043918e8b519a32072a0d",
       "value": " 28.0/28.0 [00:00&lt;00:00, 261B/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
